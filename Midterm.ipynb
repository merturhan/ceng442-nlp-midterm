{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515e93b-95ce-4547-93a5-e64af2ffed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8463d-d38c-4794-9dc3-762b1b361b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5371709-6d51-49ea-9596-275cb3d5a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "dataset = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78102ae-321f-4b59-a520-cd8c91815537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72848e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Emoji Cleaner Regex\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           u\"\\U0001f926-\\U0001f937\"\n",
    "                           u\"\\U00010000-\\U0010ffff\"\n",
    "                           u\"\\u2640-\\u2642\"\n",
    "                           u\"\\u2600-\\u2B55\"\n",
    "                           u\"\\u200d\"\n",
    "                           u\"\\u23cf\"\n",
    "                           u\"\\u23e9\"\n",
    "                           u\"\\u231a\"\n",
    "                           u\"\\ufe0f\"  # dingbats\n",
    "                           u\"\\u3030\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Turkish or Azerbaijani Character Regex\n",
    "turkish_or_azerbaijani_pattern = re.compile(\"[a-zA-ZğüşıöçƏəĞÜŞİÖÇ]\")\n",
    "\n",
    "\n",
    "# Clear emojis and make all lowercased\n",
    "dataset['content'] = dataset['content'].apply(lambda x: remove_emojis(str(x)).lower())\n",
    "# Filter rows where 'content' column contains Turkish or Azerbaijani characters, \n",
    "dataset = dataset[dataset['content'].apply(lambda x: bool(turkish_or_azerbaijani_pattern.search(str(x))))]\n",
    "\n",
    "\n",
    "# Reset index after filtering\n",
    "dataset.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab9d3de-cc8b-498e-af50-08e5719c30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating contents, scores and upvotes\n",
    "contents = dataset['content'].values.tolist()\n",
    "scores = dataset['score'].values.tolist()\n",
    "upvotes = dataset['upvotes'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7ee6cd-31ac-41be-8df8-11df0851240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "split_point = int(len(contents) * 0.8)\n",
    "\n",
    "train_contents, test_contents = contents[:split_point], contents[split_point:]\n",
    "train_scores, test_scores = scores[:split_point], scores[split_point:]\n",
    "train_upvotes, test_upvotes = upvotes[:split_point], upvotes[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1298cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
